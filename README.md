# ai-twin-lite

A simplified, educational version of an LLM Twin system inspired by the **LLM Engineers Handbook**.  
This project is designed to be internship-ready, demonstrating my skills in **data engineering**(chapter 3),  
**feature pipelines**(chapter 1 & 4), **vector databases**(chapter 4 & 9), and **RAG (Retrieval-Augmented Generation)**(chapter 9).

---

## ğŸš€ Overview

`ai-twin-lite` is a small, clean implementation of a modern RAG pipeline:

1. **Data Pipeline**  
   - Crawl or load documents  
   - Clean and normalize text  
   - Convert to structured document format

<!-- 2. **Feature Pipeline**  
   - Chunk documents  
   - Generate embeddings  
   - Store in a vector database (Qdrant)

3. **RAG Inference Pipeline**  
   - Query expansion  
   - Self-querying (metadata extraction)  
   - Vector search  
   - Cross-encoder reranking  
   - Return top relevant chunks for an LLM to answer

4. **Deployment**  
   - FastAPI backend or Gradio UI -->

This repo is intentionally lightweight so I can learn, iterate, and showcase my ML engineering skills.

---

## ğŸ“ Project Structure
<!-- â”‚  â”œâ”€ feature_pipeline/
â”‚  â”‚  â”œâ”€ chunking.py
â”‚  â”‚  â”œâ”€ embeddings.py
â”‚  â”‚  â””â”€ vector_store.py
â”‚  â”‚
â”‚  â”œâ”€ rag_pipeline/
â”‚  â”‚  â”œâ”€ query_expansion.py
â”‚  â”‚  â”œâ”€ self_query.py
â”‚  â”‚  â”œâ”€ reranker.py
â”‚  â”‚  â””â”€ rag_pipeline.py
â”‚  â”‚
â”‚  â””â”€ config.py
â”‚
â”œâ”€ app/
â”‚  â”œâ”€ api.py
â”‚  â””â”€ ui.py
â”‚
â”œâ”€ data/
â”‚  â”œâ”€ raw/
â”‚  â”œâ”€ clean/
â”‚  â””â”€ embedded/
â”‚
â”œâ”€ notebooks/ -->
```
ai-twin-lite/
â”œâ”€ src/
â”‚  â”œâ”€ data_pipeline/
â”‚  â”‚  â”œâ”€ crawler.py
â”‚  â”‚  â”œâ”€ cleaning.py
â”‚  â”‚  â””â”€ models.py
â”‚  â”‚

â”‚
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## ğŸ”§ Installation

```bash
git clone https://github.com/dblue03333/ai-twin-lite.git
cd ai-twin-lite
python3 -m venv venv
source venv/bin/activate   # or Windows: venv\Scripts\activate
pip install -r requirements.txt
```

---

## ğŸ§± Pipelines

### **1. Data Pipeline**
Implemented in `src/data_pipeline/`:

- `crawler.py` â†’ simple web/data loader  
- `cleaning.py` â†’ remove noise, normalize text  
- `models.py` â†’ Pydantic `ArticleDocument`

<!-- ### **2. Feature Pipeline**
Implemented in `src/feature_pipeline/`:

- `chunking.py` â†’ split documents into chunks  
- `embeddings.py` â†’ convert chunks into vectors  
- `vector_store.py` â†’ save vectors to Qdrant  

### **3. RAG Pipeline**
Implemented in `src/rag_pipeline/`:

- `query_expansion.py` â†’ generate expanded queries  
- `self_query.py` â†’ extract metadata from query  
- `reranker.py` â†’ cross-encoder ranking  
- `rag_pipeline.py` â†’ full inference flow   -->

---

## â–¶ï¸ Running the Feature Pipeline
<!-- 
```bash
python feature_pipeline.py
```

(Or create a dedicated runner later.) -->

---
<!-- 
## â–¶ï¸ Running the RAG Inference API

```bash
uvicorn app.api:app --reload
``` -->

---

## ğŸŒ Deployment Targets

- **Hugging Face Spaces (Gradio UI)**
- **Render (FastAPI app)**
- **Vercel (Serverless Python)**

---

## ğŸ“š Inspired By

This project is based on concepts from the  
**LLM Engineers Handbook â€“ Feature Pipelines, RAG Inference, and Data Engineering chapters**.

---

## ğŸ’¼ For Your Resume

**Tech Used:**  
Python, Pydantic, SentenceTransformers, Qdrant, FastAPI, Gradio

**Highlights:**  
- Designed and implemented an endâ€‘toâ€‘end RAG system  
- Built modular feature + inference pipelines  
- Deployed a lightweight LLM Twin for real usage  
- Demonstrated ML engineering, data engineering, and LLM application skills  

---

## ğŸ¤ Contributions

This is a learning-focused repoâ€”feel free to extend or build your own version of an AI Twin.

